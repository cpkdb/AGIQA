# LLMé€€åŒ–Promptç”ŸæˆåŠŸèƒ½ä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

æœ¬é¡¹ç›®æ–°å¢äº†åŸºäºLLMï¼ˆå¦‚GPT-4oï¼‰çš„è´¨é‡é€€åŒ–promptç”ŸæˆåŠŸèƒ½ï¼Œä½œä¸ºåŸæœ‰å…³é”®è¯æ–¹æ³•çš„å¢å¼ºç‰ˆæœ¬ã€‚

### ä¸¤ç§æ–¹æ³•å¯¹æ¯”

| ç»´åº¦ | å…³é”®è¯æ–¹æ³• | **LLMæ–¹æ³•** |
|------|-----------|-------------|
| **å¤šæ ·æ€§** | å›ºå®šå…³é”®è¯åˆ—è¡¨ï¼Œå¤šæ ·æ€§æœ‰é™ | æ¯æ¬¡ç”Ÿæˆä¸åŒè¡¨è¾¾ï¼Œå¤šæ ·æ€§æé«˜ |
| **è‡ªç„¶æ€§** | ç®€å•æ‹¼æ¥å…³é”®è¯ï¼Œå¯èƒ½ä¸å¤Ÿè‡ªç„¶ | LLMä¿è¯è¯­è¨€æµç•…è‡ªç„¶ |
| **å¯¹é½åº¦é€€åŒ–** | æœªçœŸæ­£å®ç°ï¼Œè¿”å›åŸprompt | å¯æ™ºèƒ½æ›¿æ¢å¯¹è±¡/é¢œè‰²/åŠ¨ä½œç­‰ |
| **æˆæœ¬** | å…è´¹ | éœ€è¦APIè°ƒç”¨è´¹ç”¨ |
| **é€Ÿåº¦** | æå¿«ï¼ˆæ¯«ç§’çº§ï¼‰ | è¾ƒæ…¢ï¼ˆç§’çº§ï¼Œä¾èµ–APIï¼‰ |
| **å¯æ§æ€§** | é«˜åº¦å¯æ§ | ä¾èµ–LLMç†è§£èƒ½åŠ› |

### è¾“å…¥å±‚çº§

LLMæ–¹æ³•ä½¿ç”¨**å­ç±»åˆ«ï¼ˆsubcategoryï¼‰çº§åˆ«**ä½œä¸ºè¾“å…¥ï¼Œè€Œä¸æ˜¯å…·ä½“çš„å±æ€§ï¼š

- **Visual Qualityç±»ï¼ˆ3ä¸ªå­ç±»åˆ«ï¼‰**ï¼š
  - `low_visual_quality` - æŠ€æœ¯è´¨é‡é—®é¢˜ï¼ˆblur/noise/exposureç­‰ï¼‰
  - `aesthetic_quality` - å®¡ç¾è´¨é‡ï¼ˆcomposition/lightingç­‰ï¼‰
  - `semantic_plausibility` - è¯­ä¹‰åˆç†æ€§ï¼ˆanatomy/physicsç­‰ï¼‰

- **Alignmentç±»ï¼ˆ4ä¸ªå­ç±»åˆ«ï¼‰**ï¼š
  - `basic_recognition` - åŸºç¡€è¯†åˆ«ï¼ˆä¸»è¦/æ¬¡è¦å¯¹è±¡ï¼‰
  - `attribute_alignment` - å±æ€§å¯¹é½ï¼ˆé¢œè‰²/å½¢çŠ¶/åŠ¨ä½œç­‰ï¼‰
  - `composition_interaction` - ç»„åˆäº¤äº’ï¼ˆæ•°é‡/ä½ç½®/å¤§å°ï¼‰
  - `external_knowledge` - å¤–éƒ¨çŸ¥è¯†ï¼ˆåœ°ç†/å“ç‰Œ/é£æ ¼ï¼‰

## å®‰è£…ä¾èµ–

```bash
# å®‰è£…OpenAIåº“
pip install openai

# æˆ–ä½¿ç”¨é¡¹ç›®requirements
pip install -r requirements.txt
```

## é…ç½®APIå¯†é’¥

### æ–¹æ³•1: ç¯å¢ƒå˜é‡ï¼ˆæ¨èï¼‰

```bash
export OPENAI_API_KEY="your-api-key-here"
```

å°†æ­¤è¡Œæ·»åŠ åˆ° `~/.bashrc` æˆ– `~/.zshrc` ä»¥æ°¸ä¹…ä¿å­˜ï¼š

```bash
echo 'export OPENAI_API_KEY="your-api-key-here"' >> ~/.bashrc
source ~/.bashrc
```

### æ–¹æ³•2: ç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼ˆä¸æ¨èï¼‰

ç¼–è¾‘ `data_generation/config/llm_config.yaml`:

```yaml
llm:
  api_key: "your-api-key-here"  # ç›´æ¥å¡«å†™ï¼ˆä¸è¦æäº¤åˆ°gitï¼‰
```

âš ï¸ **æ³¨æ„**ï¼šä¸è¦å°†åŒ…å«çœŸå®APIå¯†é’¥çš„é…ç½®æ–‡ä»¶æäº¤åˆ°gitä»“åº“ï¼

## é…ç½®è¯´æ˜

ç¼–è¾‘ `data_generation/config/llm_config.yaml` æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼š

```yaml
llm:
  provider: "openai"              # APIæä¾›å•†
  model: "gpt-4o"                 # ä½¿ç”¨çš„æ¨¡å‹
  temperature: 0.7                # åˆ›é€ æ€§æ§åˆ¶ï¼ˆ0.5-0.9æ¨èï¼‰
  max_tokens: 150                 # æœ€å¤§ç”Ÿæˆé•¿åº¦
  timeout: 30                     # è¯·æ±‚è¶…æ—¶æ—¶é—´
  max_retries: 3                  # å¤±è´¥é‡è¯•æ¬¡æ•°

degradation:
  fallback_to_keywords: true      # APIå¤±è´¥æ—¶å›é€€åˆ°å…³é”®è¯æ–¹æ³•
  validate_output: true           # éªŒè¯LLMè¾“å‡ºè´¨é‡
```

### æ¨èé…ç½®

- **é«˜è´¨é‡ + é«˜æˆæœ¬**: `gpt-4o`, temperature=0.7
- **å¹³è¡¡**: `gpt-4o-mini`, temperature=0.7
- **ä½æˆæœ¬**: `gpt-3.5-turbo`, temperature=0.8

## ä½¿ç”¨æ–¹æ³•

### 1. æµ‹è¯•LLMåŠŸèƒ½

```bash
cd /root/ImageReward/data_generation/scripts

# åŸºç¡€æµ‹è¯•
python test_llm_degradation.py --test basic

# å¯¹æ¯”LLM vs å…³é”®è¯æ–¹æ³•
python test_llm_degradation.py --test comparison

# æ‰¹é‡ç”Ÿæˆæµ‹è¯•
python test_llm_degradation.py --test batch

# å…¨éƒ¨æµ‹è¯•
python test_llm_degradation.py --test all
```

### 2. åœ¨æ•°æ®é›†ç”Ÿæˆä¸­ä½¿ç”¨LLM

```bash
cd /root/ImageReward/data_generation/scripts

# ä½¿ç”¨LLMç”Ÿæˆé€€åŒ–prompt
python generate_dataset.py \
  --source_prompts /path/to/prompts.json \
  --output_dir /root/autodl-tmp/dataset_llm \
  --num_negatives_per_positive 10 \
  --use_llm  # å¯ç”¨LLMæ¨¡å¼

# ä»ç„¶ä½¿ç”¨å…³é”®è¯æ–¹æ³•ï¼ˆé»˜è®¤ï¼‰
python generate_dataset.py \
  --source_prompts /path/to/prompts.json \
  --output_dir /root/autodl-tmp/dataset_keyword \
  --num_negatives_per_positive 10
  # ä¸åŠ --use_llmå‚æ•°
```

### 3. Pythonä»£ç ä¸­ä½¿ç”¨

```python
from llm_prompt_degradation import LLMPromptDegradation

# åˆå§‹åŒ–
generator = LLMPromptDegradation(
    llm_config_path="/root/ImageReward/data_generation/config/llm_config.yaml",
    quality_dimensions_path="/root/ImageReward/data_generation/config/quality_dimensions.json"
)

# ç”Ÿæˆå•ä¸ªè´Ÿæ ·æœ¬
positive_prompt = "a beautiful sunset over the ocean, high quality"
negative_prompt, degradation_info = generator.generate_negative_prompt(
    positive_prompt=positive_prompt,
    subcategory="low_visual_quality",  # å­ç±»åˆ«çº§åˆ«
    severity="moderate"
)

print(f"æ­£æ ·æœ¬: {positive_prompt}")
print(f"è´Ÿæ ·æœ¬: {negative_prompt}")
print(f"é€€åŒ–ä¿¡æ¯: {degradation_info}")

# æ‰¹é‡ç”Ÿæˆ
prompts = [
    "a red apple on the table",
    "portrait of a smiling woman",
    "modern architecture in the city"
]

results = generator.generate_batch_negatives(prompts)
for pos, neg, info in results:
    print(f"æ­£: {pos}")
    print(f"è´Ÿ: {neg}")
    print(f"é€€åŒ–: {info['dimension']} ({info['severity']})")
```

## æˆæœ¬ä¼°ç®—

åŸºäºOpenAIå®˜æ–¹å®šä»·ï¼ˆ2024å¹´ä»·æ ¼ï¼Œå¯èƒ½æœ‰å˜åŒ–ï¼‰ï¼š

| æ¨¡å‹ | è¾“å…¥ä»·æ ¼ | è¾“å‡ºä»·æ ¼ | æ¯æ¬¡è°ƒç”¨é¢„ä¼° | 10ä¸‡æ¬¡è°ƒç”¨ |
|------|---------|---------|-------------|-----------|
| gpt-4o | $2.50/1M tokens | $10.00/1M tokens | ~$0.003 | ~$300 |
| gpt-4o-mini | $0.15/1M tokens | $0.60/1M tokens | ~$0.0002 | ~$20 |
| gpt-3.5-turbo | $0.50/1M tokens | $1.50/1M tokens | ~$0.0006 | ~$60 |

**ç¤ºä¾‹è®¡ç®—**ï¼ˆç”Ÿæˆ100ä¸‡å¯¹æ•°æ®é›†ï¼‰:
- 10ä¸‡ä¸ªæ­£æ ·æœ¬ Ã— æ¯ä¸ª10ä¸ªè´Ÿæ ·æœ¬ = 100ä¸‡æ¬¡APIè°ƒç”¨
- ä½¿ç”¨gpt-4o: ~$3,000
- ä½¿ç”¨gpt-4o-mini: ~$200
- ä½¿ç”¨gpt-3.5-turbo: ~$600

ğŸ’¡ **èŠ‚çœæˆæœ¬çš„å»ºè®®**:
1. å…ˆç”¨å°‘é‡æ•°æ®æµ‹è¯•ï¼ˆ100ä¸ªæ ·æœ¬ï¼‰éªŒè¯æ•ˆæœ
2. ä½¿ç”¨ `gpt-4o-mini` è€Œé `gpt-4o`
3. å¯ç”¨ç¼“å­˜ï¼ˆåœ¨é…ç½®ä¸­è®¾ç½® `enable_cache: true`ï¼‰
4. ä»…å¯¹alignmenté€€åŒ–ä½¿ç”¨LLMï¼Œvisual_qualityä»ç”¨å…³é”®è¯æ–¹æ³•

## æ•…éšœæ’é™¤

### é—®é¢˜1: ImportError: No module named 'openai'

**è§£å†³**:
```bash
pip install openai
```

### é—®é¢˜2: APIè°ƒç”¨å¤±è´¥ - 401 Unauthorized

**åŸå› **: APIå¯†é’¥æœªè®¾ç½®æˆ–æ— æ•ˆ

**è§£å†³**:
```bash
# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY

# é‡æ–°è®¾ç½®
export OPENAI_API_KEY="sk-your-real-api-key"
```

### é—®é¢˜3: APIè°ƒç”¨è¶…æ—¶

**åŸå› **: ç½‘ç»œé—®é¢˜æˆ–APIæœåŠ¡ç¹å¿™

**è§£å†³**: é…ç½®æ–‡ä»¶ä¸­å¢åŠ è¶…æ—¶æ—¶é—´å’Œé‡è¯•æ¬¡æ•°
```yaml
llm:
  timeout: 60        # å¢åŠ åˆ°60ç§’
  max_retries: 5     # å¢åŠ é‡è¯•æ¬¡æ•°
```

### é—®é¢˜4: ç”Ÿæˆçš„è´Ÿæ ·æœ¬è´¨é‡ä¸ä½³

**è§£å†³æ–¹æ³•**:
1. è°ƒæ•´temperatureï¼ˆ0.5-0.9ä¹‹é—´å°è¯•ï¼‰
2. æ£€æŸ¥System Promptæ˜¯å¦åˆç†
3. å°è¯•ä¸åŒçš„æ¨¡å‹ï¼ˆgpt-4o vs gpt-3.5-turboï¼‰
4. å¯ç”¨è¾“å‡ºéªŒè¯ `validate_output: true`

### é—®é¢˜5: Fallbackåˆ°å…³é”®è¯æ–¹æ³•

**åŸå› **: LLM APIè°ƒç”¨å¤±è´¥åè‡ªåŠ¨é™çº§

**è§£å†³**:
- æ£€æŸ¥APIå¯†é’¥å’Œç½‘ç»œ
- å¦‚ä¸å¸Œæœ›fallbackï¼Œè®¾ç½® `fallback_to_keywords: false`

## æ€§èƒ½ä¼˜åŒ–

### 1. æ‰¹å¤„ç†

ä½¿ç”¨ `generate_batch_negatives()` è€Œéå¤šæ¬¡è°ƒç”¨å•ä¸ªç”Ÿæˆï¼š

```python
# âŒ æ…¢ï¼šå¤šæ¬¡å•ç‹¬è°ƒç”¨
for prompt in prompts:
    negative, info = generator.generate_negative_prompt(prompt, subcategory, severity)

# âœ… å¿«ï¼šæ‰¹é‡è°ƒç”¨
results = generator.generate_batch_negatives(prompts)
```

### 2. å¹¶å‘å¤„ç†

åœ¨é…ç½®ä¸­è®¾ç½®åˆç†çš„é€Ÿç‡é™åˆ¶ï¼š

```yaml
llm:
  batch_size: 10           # æ¯æ‰¹å¤„ç†10ä¸ª
  rate_limit_rpm: 60       # æ¯åˆ†é’Ÿæœ€å¤š60ä¸ªè¯·æ±‚ï¼ˆæ ¹æ®APIå¥—é¤è°ƒæ•´ï¼‰
```

### 3. ç¼“å­˜

å¯ç”¨ç¼“å­˜é¿å…é‡å¤è°ƒç”¨ç›¸åŒpromptï¼š

```yaml
degradation:
  enable_cache: true
  cache_dir: "/root/ImageReward/data_generation/.cache/llm_degradation"
```

## ä¸å…³é”®è¯æ–¹æ³•çš„æ··åˆä½¿ç”¨

æ¨èç­–ç•¥ï¼š**Visual Qualityç”¨å…³é”®è¯ï¼ŒAlignmentç”¨LLM**

åŸå› ï¼š
- Visual Qualityçš„å…³é”®è¯æ–¹æ³•å·²ç»å¾ˆæœ‰æ•ˆ
- Alignmenté€€åŒ–çš„å…³é”®è¯æ–¹æ³•æœªçœŸæ­£å®ç°ï¼Œéœ€è¦LLM

å®ç°æ–¹å¼ï¼ˆä¿®æ”¹ä»£ç ï¼‰ï¼š

```python
# åœ¨generate_dataset_with_reuseä¸­
if degradation_info['category'] == 'alignment':
    # å¯¹é½åº¦é€€åŒ–ä½¿ç”¨LLM
    negative_prompt, info = llm_generator.generate_negative_prompt(...)
else:
    # è§†è§‰è´¨é‡é€€åŒ–ä½¿ç”¨å…³é”®è¯
    negative_prompt, info = keyword_generator.generate_negative_prompt(...)
```

## è´¨é‡éªŒè¯

ç”ŸæˆåéªŒè¯è´Ÿæ ·æœ¬è´¨é‡ï¼š

```bash
# æ£€æŸ¥ç”Ÿæˆç»“æœ
python -c "
import json
with open('/root/autodl-tmp/dataset_llm/dataset.json') as f:
    data = json.load(f)

# ç»Ÿè®¡LLM vs å…³é”®è¯æ–¹æ³•
llm_count = sum(1 for p in data['pairs'] if p['degradation'].get('method') == 'llm')
keyword_count = sum(1 for p in data['pairs'] if p['degradation'].get('method') == 'keyword')

print(f'LLMæ–¹æ³•: {llm_count}')
print(f'å…³é”®è¯æ–¹æ³•: {keyword_count}')
print(f'æ€»è®¡: {len(data[\"pairs\"])}')

# æŸ¥çœ‹ç¤ºä¾‹
for pair in data['pairs'][:3]:
    print(f\"æ­£: {pair['positive']['prompt']}\")
    print(f\"è´Ÿ: {pair['negative']['prompt']}\")
    print(f\"é€€åŒ–: {pair['degradation']}\")
    print()
"
```

## æ–‡ä»¶ç»“æ„

```
data_generation/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ llm_config.yaml                 # LLMé…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ quality_dimensions.json         # è´¨é‡ç»´åº¦å®šä¹‰
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ llm_prompt_degradation.py       # LLMé€€åŒ–ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ prompt_degradation.py           # å…³é”®è¯é€€åŒ–ç”Ÿæˆå™¨
â”‚   â”œâ”€â”€ generate_dataset.py             # ä¸»ç”Ÿæˆè„šæœ¬ï¼ˆå·²é›†æˆLLMï¼‰
â”‚   â””â”€â”€ test_llm_degradation.py         # æµ‹è¯•è„šæœ¬
â””â”€â”€ LLM_DEGRADATION_GUIDE.md           # æœ¬æ–‡æ¡£
```

## ä¸‹ä¸€æ­¥

1. âœ… æµ‹è¯•LLMåŠŸèƒ½: `python test_llm_degradation.py --test all`
2. âœ… å°è§„æ¨¡éªŒè¯: ç”Ÿæˆ100å¯¹æ ·æœ¬éªŒè¯æ•ˆæœå’Œæˆæœ¬
3. â³ å¤§è§„æ¨¡ç”Ÿæˆ: ç¡®è®¤æ•ˆæœåç”Ÿæˆå®Œæ•´æ•°æ®é›†
4. â³ å¯¹æ¯”è¯„ä¼°: ä½¿ç”¨ImageRewardè¯„ä¼°ä¸¤ç§æ–¹æ³•çš„æ•ˆæœå·®å¼‚

## å‚è€ƒ

- OpenAI APIæ–‡æ¡£: https://platform.openai.com/docs/api-reference
- æœ¬é¡¹ç›®æ–‡æ¡£: `/root/ImageReward/data_generation/DATASET_GENERATION_PLAN.md`
- è´¨é‡ç»´åº¦å®šä¹‰: Section 2.2 (Visual Quality & Alignment)
